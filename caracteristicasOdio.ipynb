{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renbenj29974/EntregaFinal-Nazate/blob/main/caracteristicasOdio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Slh0_EH3Ojna"
      },
      "source": [
        "**Universidad Internacional de La Rioja (UNIR) - Máster Universitario en Inteligencia Artificial - Procesamiento del Lenguaje Natural**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CyDQCIZOjnb"
      },
      "source": [
        "***\n",
        "Datos del alumno (Nombre y Apellidos): Renán Benjamín Nazate Ortiz\n",
        "\n",
        "Fecha: 2024-05-05\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmmnThhBOjnb"
      },
      "source": [
        "<span style=\"font-size: 20pt; font-weight: bold; color: #0098cd;\">Trabajo: Actividad 1 Individual-Entity Recognition</span>\n",
        "\n",
        "**Objetivos**\n",
        "\n",
        "Con esta actividad se tratará de que el alumno se familiarice con el manejo de la librería spacy, así como con los conceptos básicos de manejo de las técnicas NER\n",
        "\n",
        "**Descripción**\n",
        "\n",
        "En esta actividad debes procesar de forma automática un texto en lenguaje natural para detectar características básicas en el mismo, y para identificar y etiquetar las ocurrencias de conceptos como localización, moneda, empresas, etc.\n",
        "\n",
        "En la primera parte del ejercicio se proporciona un código fuente a través del cual se lee un archivo de texto y se realiza un preprocesado del mismo. En esta parte el alumno tan sólo debe ejecutar y entender el código proporcionado.\n",
        "\n",
        "En la segunda parte del ejercicio se plantean una serie de preguntas que deben ser respondidas por el alumno. Cada pregunta deberá responderse con un fragmento de código fuente que esté acompañado de la explicación correspondiente. Para elaborar el código solicitado, el alumno deberá visitar la documentación de la librería spacy, cuyos enlaces se proporcionarán donde corresponda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG4BFCErPDWo",
        "outputId": "45b13f35-dcfb-4b59-c605-63189f06b6fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Código para conectar a Google Drive con una cuenta de gmail de Renán Nazate\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0fcRYTdOjnc"
      },
      "source": [
        "# Parte 1: carga y preprocesamiento del texto a analizar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "natxNHXIOjnc"
      },
      "source": [
        "Observa las diferentes librerías que se están importando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqEir6MYOjnc",
        "outputId": "809ab047-476c-43df-da12-8f262d92d85b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-md==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.7.0/es_core_news_md-3.7.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-md==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-md==3.7.0) (1.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# Cargamos librerias a utilizar\n",
        "!python -m spacy download es_core_news_md\n",
        "import pathlib\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from spacy import displacy\n",
        "import csv\n",
        "import es_core_news_md\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug9GQgYHOjnd"
      },
      "source": [
        "El siguiente código simplemente carga y preprocesa el texto. Para ello, lo primero que hace es cargar un modelo de lenguaje previamente entrenado. En este caso, se utiliza <i>es_core_news_md</i>:\n",
        "\n",
        "https://spacy.io/models/es#es_core_news_md\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "pue4FUqGOjnd"
      },
      "outputs": [],
      "source": [
        "nlp = es_core_news_md.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjXJnIpC95ji",
        "outputId": "60d649ff-d779-4b9f-9ee7-75c94ac2ab31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "02Dataset_sin_procesar.csv  caracteristicasOdio.ipynb  ISO-8859-1-comentariosOdio.csv\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/drive/MyDrive/MaestriaIA/Procesamiento de lenguaje natural/Actividad 1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRVaFq-ROjnd"
      },
      "source": [
        "El objeto <i>nlp</i> permite utilizar el modelo de lenguaje cargado, de forma que se puede procesar un texto y obtenerlo en su versión preprocesada. Así, nos permite realizar las diferentes tareas. En este caso, vamos a utilizar el pipeline para hacer un preprocesamiento básico, que consiste en tokenizar el texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27j2WpGgOjnd",
        "outputId": "6f8b4dc5-2702-4740-8486-8711324a60e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      MEDIO SOPORTE                                                URL  \\\n",
            "0  EL PAÍS      WEB  https://elpais.com/deportes/2021-01-20/alcoyan...   \n",
            "1  EL PAÍS      WEB  https://elpais.com/deportes/2021-01-20/alcoyan...   \n",
            "2  EL PAÍS      WEB  https://elpais.com/espana/2021-01-18/comienza-...   \n",
            "3  EL PAÍS      WEB  https://elpais.com/espana/2021-01-18/comienza-...   \n",
            "4  EL PAÍS      WEB  https://elpais.com/espana/2021-01-18/comienza-...   \n",
            "\n",
            "  TIPO DE MENSAJE                               CONTENIDO A ANALIZAR  \\\n",
            "0      COMENTARIO  el barça nunca acaeza ante un segundo b ni ant...   \n",
            "1      COMENTARIO  el real madrid ha puesto punto y final a su an...   \n",
            "2      COMENTARIO  cristina cifuentes podría haber sido la presid...   \n",
            "3      COMENTARIO  habría que reabrir el caso. el supremo se dedi...   \n",
            "4      COMENTARIO  me parece un poco exagerado pedir más de tres ...   \n",
            "\n",
            "   INTENSIDAD TIPO DE ODIO TONO HUMORISTICO MODIFICADOR  Unnamed: 9  \\\n",
            "0         3.0        Otros              NaN         NaN         NaN   \n",
            "1         0.0          NaN              NaN         NaN         NaN   \n",
            "2         3.0   Ideológico              NaN         NaN         NaN   \n",
            "3         3.0   Ideológico              NaN         NaN         NaN   \n",
            "4         3.0   Ideológico               Si         NaN         NaN   \n",
            "\n",
            "   Unnamed: 10  Unnamed: 11  Unnamed: 12  Unnamed: 13  Unnamed: 14  \\\n",
            "0          NaN          NaN          NaN          NaN          NaN   \n",
            "1          NaN          NaN          NaN          NaN          NaN   \n",
            "2          NaN          NaN          NaN          NaN          NaN   \n",
            "3          NaN          NaN          NaN          NaN          NaN   \n",
            "4          NaN          NaN          NaN          NaN          NaN   \n",
            "\n",
            "   Unnamed: 15  \n",
            "0          NaN  \n",
            "1          NaN  \n",
            "2          NaN  \n",
            "3          NaN  \n",
            "4          NaN  \n"
          ]
        }
      ],
      "source": [
        "# Especifica la ruta al archivo CSV que contiene la data\n",
        "filename = \"/content/drive/MyDrive/MaestriaIA/Procesamiento de lenguaje natural/Actividad 1/02Dataset_sin_procesar.csv\"\n",
        "# Define el número de líneas que deseas leer del archivo para limitar la carga de datos a 2000 registros.\n",
        "# Esto es útil para no sobrecargar la memoria al trabajar con grandes conjuntos de datos.\n",
        "lines_number = 2000\n",
        "# Carga los datos desde el archivo CSV, utilizando ';' como delimitador.\n",
        "# Se usa 'encoding=ISO-8859-1' para manejar correctamente caracteres especiales.\n",
        "# 'low_memory=False' se usa para minimizar el riesgo de tipos de datos incorrectos al procesar grandes archivos.\n",
        "data = pd.read_csv(filename, delimiter=';',  low_memory=False, encoding='ISO-8859-1',nrows=lines_number)\n",
        "# Imprime las primeras filas de la data para verificar que se haya cargado correctamente.\n",
        "# Esto es útil para hacer una inspección rápida de los datos.\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWhJb9jxOjnd"
      },
      "source": [
        "### Playground\n",
        "\n",
        "Utiliza este espacio para hacer pruebas y ensayos con las variables generadas con el código previo. A modo de ejemplo, se ofrece código que realiza las siguientes tareas:\n",
        "\n",
        "\n",
        "- leer un número dado de líneas del Dataframe y generar dos listas con los valores (se pueden leer directamente del DataFrame, se muestra el ejemplo como una opción más)\n",
        "- procesar el texto de cada comentario\n",
        "\n",
        "\n",
        "Para procesarlo, hay utilizar el objeto <i>nlp</i> y así obtener objetos de la clase <i>Doc</i> (https://spacy.io/api/doc)\n",
        "\n",
        "Visita la documentación de dicha clase y experimenta probando las diferentes funciones y atributos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vUyfrY5Ojnd"
      },
      "outputs": [],
      "source": [
        "# Puedes insertar aquí código de pruebas para experimentar con las diferentes funciones y atributos de 'doc'.\n",
        "#print(data[\"CONTENIDO A ANALIZAR\"][1])\n",
        "#print(data[\"INTENSIDAD\"][1])\n",
        "doc = []\n",
        "value = []\n",
        "\n",
        "#con el bucle, generamos sendas listas con los comentarios ya parseados y con el valor de intensidad\n",
        "for i in range(0, lines_number):\n",
        "\n",
        "    #en un primer paso se parsea el comentario. En el segundo paso se añade el objeto a la lista\n",
        "    tmp_doc = nlp(data[\"CONTENIDO A ANALIZAR\"][i])\n",
        "    doc.append(tmp_doc)\n",
        "\n",
        "    #en un primer paso extrae el valor. En el segundo paso se añade el valor a la lista\n",
        "    tmp_value = data[\"INTENSIDAD\"][i]\n",
        "    value.append(tmp_value)\n",
        "\n",
        "\n",
        "#ejemplo de cómo recorrer un comentario palabra por palabra\n",
        "for token in doc[1]:\n",
        "    print(token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMwATxi-Ojne"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 1.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuántos registros contiene el corpus?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQbs-G6AOjne",
        "outputId": "1f328935-b12a-4b34-a861-a659e6c97cab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de registros del corpus: 2000\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "# Contar cuántos registros hay en el corpus\n",
        "numero_registros = len(data)\n",
        "print(\"Cantidad de registros del corpus:\", numero_registros)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXBJKlDwOjne"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Utilizamos len para contar los registros del corpus\n",
        "2. Imprimimos resultados con print"
      ],
      "metadata": {
        "id": "lQfd8NY1-ADQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp2JNLGYOjne"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 2.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuántas palabras totales hay en los comentarios del corpus?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PAQ1JrVOjne",
        "outputId": "656b354e-ea85-4d16-c5d7-bb8c08ffb64f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El total de palabras en los comentarios del corpus es: 45567\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "# Cargamos el modelo de Spacy\n",
        "nlp = spacy.load(\"es_core_news_md\")\n",
        "\n",
        "# Función para contar palabras, excluyendo puntuaciones y palabras de parada\n",
        "def contar_palabras(text):\n",
        "    doc = nlp(text)\n",
        "    words = [token.text for token in doc if not token.is_punct and not token.is_stop]\n",
        "    return len(words)\n",
        "\n",
        "# Se aplica la función a cada comentario en el DataFrame\n",
        "data['palabra_contar'] = data['CONTENIDO A ANALIZAR'].apply(contar_palabras)\n",
        "\n",
        "# Calcular el total de palabras en el corpus\n",
        "total_palabras = data['palabra_contar'].sum()\n",
        "print(f\"El total de palabras en los comentarios del corpus es: {total_palabras}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T4UkihlOjne"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. En el foro se explica que la columna a utilizar como comentarios es \"CONTENIDO A ANALIZAR\"\n",
        "2. Se utiliza la libreria spacy con el modelo preentrenado es_core_news_md para una mayor precisión\n",
        "3. Se utiliza la función contar_palabras, para luego ser llamada mediante la columna CONTENIDO A ANALIZAR (\"comentarios\"), y asignamos su valor al arreglo data['palabra_contar']\n",
        "4. Aplicamos la variable reservada de pyhton sum para sumar todo lo que contiene el array data['palabra_contar']\n",
        "5. Imprimimos resultados\n"
      ],
      "metadata": {
        "id": "obpwVs_g-ml1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX5eoSiZOjne"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 3.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuál es el número promedio de palabras en cada comentario?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1dS4tBSOjne",
        "outputId": "5b55e848-8b2d-4dfe-b21c-5fa563864048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El número promedio de palabras por comentario es: 22.57\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "# Cargamos el modelo preentrenado\n",
        "nlp = spacy.load(\"es_core_news_md\")\n",
        "\n",
        "# Función para contar palabras, excluyendo puntuaciones y palabras de parada\n",
        "def contar_palabras(text):\n",
        "    doc = nlp(text)\n",
        "    # Considerar solo tokens que no son puntuaciones ni espacios, y no son palabras de parada\n",
        "    palabras = [token.text for token in doc if not token.is_punct and not token.is_space and not token.is_stop]\n",
        "    return len(palabras)\n",
        "\n",
        "# Se aplica la función a cada comentario en el DataFrame\n",
        "data['palabra_contar'] = data['CONTENIDO A ANALIZAR'].apply(contar_palabras)\n",
        "\n",
        "# Calcular el promedio de palabras por comentario\n",
        "promedio_palabras_por_comentario = data['palabra_contar'].mean()\n",
        "print(f\"El número promedio de palabras por comentario es: {promedio_palabras_por_comentario:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVTsXpuzyMPl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgbYsdweOjne"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. En el foro se explica que la columna a utilizar como comentarios es \"CONTENIDO A ANALIZAR\"\n",
        "2. Se utiliza la libreria spacy con el modelo preentrenado es_core_news_md para una mayor precisión\n",
        "3. Se utiliza la función contar_palabras, para luego ser llamada mediante la columna CONTENIDO A ANALIZAR (\"comentarios\") y asignamos su valor al arreglo data['palabra_contar']\n",
        "4. Aplicamos la variable reservada de pyhton mean para calcular el  el promedio por comentario a todo lo que contiene el arreglo data['palabra_contar'].\n",
        "5. Imprimimos resultados"
      ],
      "metadata": {
        "id": "lLjBZlvdB8QE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6D1IwnfOjne"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 4.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¿Cuál es el número promedio de palabras en los comentarios de cada grupo?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B5GgzWLOjne",
        "outputId": "141760eb-c89e-4f07-a2e1-19efc002c912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El número promedio de palabras por comentario en el grupo 'No Odio' es: 29.73\n",
            "El número promedio de palabras por comentario en el grupo 'Odio' es: 10.57\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "# Cargamos el modelo de Spacy\n",
        "nlp = spacy.load(\"es_core_news_md\")\n",
        "\n",
        "# Función para contar palabras, excluyendo puntuaciones y palabras de parada\n",
        "def contar_palabras(text):\n",
        "    doc = nlp(text)\n",
        "    # Considerar solo tokens que no son puntuaciones ni espacios, y no son palabras de parada\n",
        "    palabras = [token.text for token in doc if not token.is_punct and not token.is_space and not token.is_stop]\n",
        "    return len(palabras)\n",
        "\n",
        "# Aplicamos la función a cada comentario en el DataFrame\n",
        "data['palabra_contar'] = data['CONTENIDO A ANALIZAR'].apply(contar_palabras)\n",
        "\n",
        "# Segmentar los datos en dos grupos basados en la 'INTENSIDAD'\n",
        "data_no_odio = data[data['INTENSIDAD'] == 0]\n",
        "data_odio = data[data['INTENSIDAD'] > 0]\n",
        "\n",
        "# Calcular el promedio de palabras por comentario en cada grupo\n",
        "promedio_palabras_por_comentario_no_odio = data_no_odio['palabra_contar'].mean()\n",
        "promedio_palabras_por_comentario_odio = data_odio['palabra_contar'].mean()\n",
        "\n",
        "print(f\"El número promedio de palabras por comentario en el grupo 'No Odio' es: {promedio_palabras_por_comentario_no_odio:.2f}\")\n",
        "print(f\"El número promedio de palabras por comentario en el grupo 'Odio' es: {promedio_palabras_por_comentario_odio:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2lKeSekOjne"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. En el foro se explica que la columna a utilizar como comentarios es \"CONTENIDO A ANALIZAR\"\n",
        "2. Se utiliza la libreria spacy con el modelo preentrenado es_core_news_md para una mayor precisión\n",
        "3. Se utiliza la función contar_palabras, para luego ser llamada mediante la columna CONTENIDO A ANALIZAR (\"comentarios\"), y asignamos su valor al arreglo data['palabra_contar']\n",
        "4. Segmentamos los datos en 2 grupos basados en la Intensidad data_no_odio y data_odio.\n",
        "5. Aplicamos la variable reservada de pyhton mean para calcular el primedio y asignamos ese valor a la variables promedio_palabras_por_comentario_no_odio, promedio_palabras_por_comentario_odio respectivamente.\n",
        "6. Imprimimos los resultados"
      ],
      "metadata": {
        "id": "mkr09OtwDJ4S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNZUaamIOjnf"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 5.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¿Cuál es el número promedio de oraciones en los comentarios de cada grupo?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHd01HF5Ojnf",
        "outputId": "567fce87-7fed-4232-d910-3c485f7c52c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El número promedio de oraciones por comentario en el grupo 'No Odio' es: 3.32\n",
            "El número promedio de oraciones por comentario en el grupo 'Odio' es: 1.81\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "# Cargar el modelo de Spacy\n",
        "nlp = spacy.load(\"es_core_news_md\")\n",
        "\n",
        "# Función para contar oraciones en un comentario\n",
        "def contar_oraciones(text):\n",
        "    doc = nlp(text)\n",
        "    # Cuenta todas las oraciones en el documento\n",
        "    oraciones = list(doc.sents)\n",
        "    return len(oraciones)\n",
        "\n",
        "# Aplicar la función para contar oraciones a cada comentario en el DataFrame\n",
        "data['oracion_contar'] = data['CONTENIDO A ANALIZAR'].apply(contar_oraciones)\n",
        "\n",
        "# Segmentar los datos en dos grupos basados en la 'INTENSIDAD'\n",
        "data_no_odio = data[data['INTENSIDAD'] == 0]\n",
        "data_odio = data[data['INTENSIDAD'] > 0]\n",
        "\n",
        "# Calcular el promedio de oraciones por comentario en cada grupo\n",
        "promedio_oraciones_por_comentario_no_odio = data_no_odio['oracion_contar'].mean()\n",
        "promedio_oraciones_por_comentario_odio = data_odio['oracion_contar'].mean()\n",
        "\n",
        "print(f\"El número promedio de oraciones por comentario en el grupo 'No Odio' es: {promedio_oraciones_por_comentario_no_odio:.2f}\")\n",
        "print(f\"El número promedio de oraciones por comentario en el grupo 'Odio' es: {promedio_oraciones_por_comentario_odio:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICJr823yOjnf"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. En el foro se explica que la columna a utilizar como comentarios es \"CONTENIDO A ANALIZAR\"\n",
        "2. Se utiliza la libreria spacy con el modelo preentrenado es_core_news_md para una mayor precisión\n",
        "3. Se utiliza la función contar_oraciones, para luego ser llamada mediante la columna CONTENIDO A ANALIZAR (\"comentarios\"), y asignamos su valor al arreglo data['oracion_contar']\n",
        "4. Segmentamos los datos en 2 grupos basados en la Intensidad data_no_odio y data_odio.\n",
        "5. Aplicamos la variable reservada de pyhton mean para calcular el primedio y asignamos ese valor a la variables promedio_oraciones_por_comentario_no_odio, promedio_orqaciones_por_comentario_odio respectivamente.\n",
        "6. Imprimimos los resultados"
      ],
      "metadata": {
        "id": "O1Ph2J_TFdF8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rksmCW3UOjnf"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 6.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¿Cuál es el porcentaje de comentarios que contienen entidades NER en cada grupo?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF-RQkkgOjnf",
        "outputId": "598c3721-45e5-45c4-ebb9-a775e8e1896f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porcentaje de comentarios que contienen entidades NER en el grupo 'No Odio': 42.49%\n",
            "Porcentaje de comentarios que contienen entidades NER en el grupo 'Odio': 37.30%\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "# Cargamos el modelo de Spacy\n",
        "nlp = spacy.load(\"es_core_news_md\")\n",
        "\n",
        "# Función para detectar si un comentario contiene al menos una entidad NER\n",
        "def contiene_ner(text):\n",
        "    doc = nlp(text)\n",
        "    return len(doc.ents) > 0  # Retorna True si hay al menos una entidad, False de lo contrario\n",
        "\n",
        "# Aplicar la función para detectar entidades a cada comentario en el DataFrame\n",
        "data['Contiene_NER'] = data['CONTENIDO A ANALIZAR'].apply(contiene_ner)\n",
        "\n",
        "# Segmentar los datos en dos grupos basados en la 'INTENSIDAD'\n",
        "data_no_odio = data[data['INTENSIDAD'] == 0]\n",
        "data_odio = data[data['INTENSIDAD'] > 0]\n",
        "\n",
        "# Calcular el porcentaje de comentarios que contienen entidades NER en cada grupo\n",
        "porcentaje_con_ner_no_odio = 100 * data_no_odio['Contiene_NER'].mean()\n",
        "porcentaje_con_ner_odio = 100 * data_odio['Contiene_NER'].mean()\n",
        "\n",
        "print(f\"Porcentaje de comentarios que contienen entidades NER en el grupo 'No Odio': {porcentaje_con_ner_no_odio:.2f}%\")\n",
        "print(f\"Porcentaje de comentarios que contienen entidades NER en el grupo 'Odio': {porcentaje_con_ner_odio:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PNFFnJAOjnf"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. En el foro se explica que la columna a utilizar como comentarios es \"CONTENIDO A ANALIZAR\"\n",
        "2. Se utiliza la libreria spacy con el modelo preentrenado es_core_news_md para una mayor precisión\n",
        "3. Se utiliza la función contiene_ner para detectar si un comentatio contiene al menos una entidad NER, esta función es llamada mediante la columna CONTENIDO A ANALIZAR (\"comentarios\"), y asignamos su valor al arreglo data['Contiene_NER']\n",
        "4. Segmentamos los datos en 2 grupos basados en la Intensidad data_no_odio y data_odio.\n",
        "5. Aplicamos la variable reservada de pyhton mean para calcular el promedio multiplicado por 100 para calcular el porcentahe y asignamos ese valor a las variables promedio_oraciones_por_comentario_no_odio, promedio_oraciones_por_comentario_odio respectivamente.\n",
        "6. Imprimimos los resultados"
      ],
      "metadata": {
        "id": "7fpPHitPHCAy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxCzS1OWOjnf"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 7.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¿Cuál es el porcentaje de comentarios que contienen entidades NER de tipo PERSON en cada grupo?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1j1p5BYOjnf",
        "outputId": "1d9ea2df-95f4-425f-d074-2c2a6e471009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porcentaje de comentarios que contienen entidades NER de tipo PERSON en el grupo 'No Odio': 26.04%\n",
            "Porcentaje de comentarios que contienen entidades NER de tipo PERSON en el grupo 'Odio': 20.05%\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "# Cargar el modelo de spaCy para procesamiento de lenguaje natural\n",
        "nlp = spacy.load(\"es_core_news_md\")\n",
        "\n",
        "# Función para detectar si un comentario contiene al menos una entidad NER de tipo PERSON\n",
        "def contiene_person_ner(text):\n",
        "    doc = nlp(text)\n",
        "    # Verificar si hay al menos una entidad de tipo PERSON en el documento\n",
        "    return any(ent.label_ == 'PER' for ent in doc.ents)\n",
        "\n",
        "# Aplicar la función para detectar entidades de tipo PERSON en cada comentario del DataFrame\n",
        "data['Contiene_PERSON_NER'] = data['CONTENIDO A ANALIZAR'].apply(contiene_person_ner)\n",
        "\n",
        "# Segmentar los datos en dos grupos basados en la 'INTENSIDAD'\n",
        "data_no_odio = data[data['INTENSIDAD'] == 0]\n",
        "data_odio = data[data['INTENSIDAD'] > 0]\n",
        "\n",
        "# Calcular el porcentaje de comentarios que contienen entidades NER de tipo PERSON en cada grupo\n",
        "porcentaje_con_person_ner_no_odio = 100 * data_no_odio['Contiene_PERSON_NER'].mean()\n",
        "porcentaje_con_person_ner_odio = 100 * data_odio['Contiene_PERSON_NER'].mean()\n",
        "\n",
        "print(f\"Porcentaje de comentarios que contienen entidades NER de tipo PERSON en el grupo 'No Odio': {porcentaje_con_person_ner_no_odio:.2f}%\")\n",
        "print(f\"Porcentaje de comentarios que contienen entidades NER de tipo PERSON en el grupo 'Odio': {porcentaje_con_person_ner_odio:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyc8qusGOjnf"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. En el foro se explica que la columna a utilizar como comentarios es \"CONTENIDO A ANALIZAR\"\n",
        "2. Se utiliza la libreria spacy con el modelo preentrenado es_core_news_md para una mayor precisión\n",
        "3. Se utiliza la función contiene_person_ner para detectar si un comentario contiene al menos una entidad NER de tipo PERSON, esta función es llamada mediante la columna CONTENIDO A ANALIZAR (\"comentarios\"), y asignamos su valor al arreglo data['Contiene_PERSON_NER']\n",
        "4. Segmentamos los datos en 2 grupos basados en la Intensidad data_no_odio y data_odio.\n",
        "5. Aplicamos la variable reservada de pyhton mean para calcular el promedio multiplicado por 100 para calcular el porcentaje y asignamos ese valor a las variables porcentaje_con_person_ner_no_odio, porcentaje_con_person_ner_odio respectivamente.\n",
        "6. Imprimimos los resultados"
      ],
      "metadata": {
        "id": "vqnY_I-iJC1_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIIV8nbEOjnf"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 8.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio) ¿Cuál es el porcentaje de palabras en cada combinación posible de género y número (p.ej. masculino singular) en cada grupo?</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrGn1zV_Ojnf",
        "outputId": "3b941ab1-93d9-4b9e-df22-c9442e58c237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porcentaje de palabras por género y número en el grupo 'No Odio':\n",
            "('Masc', 'Sing'): 26.62%\n",
            "('Fem', 'Sing'): 23.09%\n",
            "('Unknown', 'Unknown'): 16.53%\n",
            "('Unknown', 'Plur'): 4.95%\n",
            "('Fem', 'Plur'): 6.87%\n",
            "('Unknown', 'Sing'): 10.71%\n",
            "('Masc', 'Plur'): 10.74%\n",
            "('Fem', 'Unknown'): 0.16%\n",
            "('Masc', 'Unknown'): 0.33%\n",
            "\n",
            "Porcentaje de palabras por género y número en el grupo 'Odio':\n",
            "('Masc', 'Sing'): 25.99%\n",
            "('Fem', 'Sing'): 23.36%\n",
            "('Masc', 'Plur'): 13.02%\n",
            "('Unknown', 'Plur'): 6.42%\n",
            "('Unknown', 'Unknown'): 13.64%\n",
            "('Unknown', 'Sing'): 11.20%\n",
            "('Fem', 'Plur'): 6.13%\n",
            "('Masc', 'Unknown'): 0.14%\n",
            "('Fem', 'Unknown'): 0.10%\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "# Cargar el modelo de spaCy para procesamiento de lenguaje natural\n",
        "nlp = spacy.load(\"es_core_news_md\")\n",
        "\n",
        "# Función para analizar género y número de cada palabra\n",
        "def analiza_genero_numero(text):\n",
        "    doc = nlp(text)\n",
        "    genero_numero = Counter()\n",
        "    # Analizar cada token en el documento\n",
        "    for token in doc:\n",
        "        if token.pos_ in ['NOUN', 'PRON', 'ADJ']:  # Focalizar en sustantivos, pronombres y adjetivos\n",
        "            gender = token.morph.get('Gender') or ['Unknown']  # Obtener género, 'Unknown' si no está disponible\n",
        "            number = token.morph.get('Number') or ['Unknown']  # Obtener número, 'Unknown' si no está disponible\n",
        "            genero_numero[(gender[0], number[0])] += 1  # Contar combinaciones de género y número\n",
        "    return genero_numero\n",
        "\n",
        "# Aplicar la función a cada comentario y sumar todos los contadores por grupo\n",
        "data['Genero_Numero'] = data['CONTENIDO A ANALIZAR'].apply(analiza_genero_numero)\n",
        "\n",
        "# Segmentar los datos en dos grupos basados en 'INTENSIDAD'\n",
        "data_no_odio = data[data['INTENSIDAD'] == 0]\n",
        "data_odio = data[data['INTENSIDAD'] > 0]\n",
        "\n",
        "# Agregar los contadores de género y número por categoría\n",
        "agregar_cuenta_no_odio = sum(data_no_odio['Genero_Numero'], Counter())\n",
        "agregar_cuenta_odio = sum(data_odio['Genero_Numero'], Counter())\n",
        "\n",
        "# Calcular porcentajes\n",
        "total_cuenta_no_odio = sum(agregar_cuenta_no_odio.values())\n",
        "total_cuenta_odio = sum(agregar_cuenta_odio.values())\n",
        "\n",
        "porcentajes_no_odio = {k: (v / total_cuenta_no_odio * 100) for k, v in agregar_cuenta_no_odio.items()}\n",
        "percentajes_odio = {k: (v / total_cuenta_odio * 100) for k, v in agregar_cuenta_odio.items()}\n",
        "\n",
        "print(\"Porcentaje de palabras por género y número en el grupo 'No Odio':\")\n",
        "for k, v in porcentajes_no_odio.items():\n",
        "    print(f\"{k}: {v:.2f}%\")\n",
        "\n",
        "print(\"\\nPorcentaje de palabras por género y número en el grupo 'Odio':\")\n",
        "for k, v in percentajes_odio.items():\n",
        "    print(f\"{k}: {v:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaN3SEoqOjnf"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. En el foro se explica que la columna a utilizar como comentarios es \"CONTENIDO A ANALIZAR\"\n",
        "2. Se utiliza la libreria spacy con el modelo preentrenado es_core_news_md para una mayor precisión\n",
        "3. Se utiliza la función analiza_genero_numero para analizar cada token en el documento, esta función es llamada mediante la columna CONTENIDO A ANALIZAR (\"comentarios\"), y asignamos su valor al arreglo data['Genero_Numero']\n",
        "4. Segmentamos los datos en 2 grupos basados en la Intensidad data_no_odio y data_odio.\n",
        "5. Agregamos los contadores de género y número por categoría de Odio y no odio a las variables agregar_cuenta_no_odio, agregar_cuenta_odio respectivamente.\n",
        "6. Calculamos los porcentajes y asignamos a total_cuenta_no_odio, total_cuenta_odio respectivamente mediante la función sum() de python\n",
        "7. Aplicamos el cálculo por cada items que contienen las variables total_cuenta_no_odio, total_cuenta_odio respectivamente y asignamos a porcentajes_no_odio y porcentajes_odio\n",
        "8. Imprimimos los resultados"
      ],
      "metadata": {
        "id": "SaTNsrvfKk16"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08YD_8qnOjng"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 9.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio), indica cuántas entidades de cada tipo posible se reconocen en cada uno de los grupos</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dBAd0AqOjng",
        "outputId": "680b3321-f32a-4032-9314-be7e7f78f3cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entidades por tipo en el grupo 'No Odio':\n",
            "ORG: 307\n",
            "MISC: 543\n",
            "PER: 1907\n",
            "LOC: 832\n",
            "\n",
            "Entidades por tipo en el grupo 'Odio':\n",
            "PER: 301\n",
            "MISC: 105\n",
            "ORG: 57\n",
            "LOC: 171\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "# Cargar el modelo de spaCy para procesamiento de lenguaje natural\n",
        "nlp = spacy.load(\"es_core_news_md\")\n",
        "\n",
        "# Función para extraer y contar tipos de entidades NER en un comentario\n",
        "def extrer_entidades(text):\n",
        "    doc = nlp(text)\n",
        "    entidades = Counter([ent.label_ for ent in doc.ents])  # Contar las entidades por tipo\n",
        "    return entidades\n",
        "\n",
        "# Aplicar la función para extraer y contar entidades a cada comentario en el DataFrame\n",
        "data['Entidades'] = data['CONTENIDO A ANALIZAR'].apply(extrer_entidades)\n",
        "\n",
        "# Segmentar los datos en dos grupos basados en la 'INTENSIDAD'\n",
        "data_no_odio = data[data['INTENSIDAD'] == 0]\n",
        "data_odio = data[data['INTENSIDAD'] > 0]\n",
        "\n",
        "# Agregar los contadores de entidades por tipo por categoría\n",
        "agregar_entidades_no_odio = sum(data_no_odio['Entidades'], Counter())\n",
        "agregar_entidades_odio = sum(data_odio['Entidades'], Counter())\n",
        "\n",
        "print(\"Entidades por tipo en el grupo 'No Odio':\")\n",
        "for entity, count in agregar_entidades_no_odio.items():\n",
        "    print(f\"{entity}: {count}\")\n",
        "\n",
        "print(\"\\nEntidades por tipo en el grupo 'Odio':\")\n",
        "for entity, count in agregar_entidades_odio.items():\n",
        "    print(f\"{entity}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fVXlqJiOjng"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. En el foro se explica que la columna a utilizar como comentarios es \"CONTENIDO A ANALIZAR\"\n",
        "2. Se utiliza la libreria spacy con el modelo preentrenado es_core_news_md para una mayor precisión\n",
        "3. Se utiliza la función extraer_entidades para extrare y contar tipo de entidades, esta función es llamada mediante la columna CONTENIDO A ANALIZAR (\"comentarios\"), y asignamos su valor al arreglo data['Entidades']\n",
        "4. Segmentamos los datos en 2 grupos basados en la Intensidad data_no_odio y data_odio.\n",
        "5. Agregamos los contadores de entidades por categoría de data_odio y data_no_odio a las variables agregar_entidades_no_odio, agregar_entidades_odio respectivamente, aplicando la función sum() de python\n",
        "6. Imprimimos los resultados"
      ],
      "metadata": {
        "id": "wKTQS4lNO7MI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF7B9wJuOjng"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 10.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Considerando dos grupos de comentarios (odio y no odio), extrae y muestra los 100 lemas más repetidos en los comentarios de cada grupo</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7VFaUgDOjnh",
        "outputId": "41f3daa0-1cbc-4360-c534-f4b4bf821128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los 100 lemas más repetidos en el grupo 'No Odio':\n",
            "i: 655\n",
            "per: 248\n",
            "trump: 226\n",
            "amb: 224\n",
            "el: 201\n",
            "com: 130\n",
            "més: 127\n",
            "és: 120\n",
            "año: 117\n",
            "dels: 115\n",
            "voto: 102\n",
            "però: 99\n",
            "país: 96\n",
            "biden: 91\n",
            "ver: 83\n",
            "cosa: 79\n",
            "quedar: 77\n",
            "tot: 75\n",
            "pasar: 71\n",
            "ganar: 70\n",
            "seguir: 68\n",
            "presidente: 66\n",
            "hi: 65\n",
            "haber: 64\n",
            "caso: 63\n",
            "político: 62\n",
            "millón: 61\n",
            "mundo: 57\n",
            "tiempo: 56\n",
            "fer: 55\n",
            "casa: 55\n",
            "pensar: 54\n",
            "llegar: 54\n",
            "querer: 54\n",
            "seva: 54\n",
            "esperar: 54\n",
            "anys: 53\n",
            "gobierno: 51\n",
            "persona: 51\n",
            "pedir: 51\n",
            "poner: 49\n",
            "elección: 49\n",
            "tener: 49\n",
            "decir: 48\n",
            "seu: 48\n",
            "españa: 47\n",
            "després: 47\n",
            "gente: 46\n",
            "acabar: 46\n",
            "deber: 46\n",
            "partido: 45\n",
            "vida: 43\n",
            "sistema: 43\n",
            "als: 43\n",
            "vacuna: 43\n",
            "salir: 42\n",
            "general: 42\n",
            "poder: 42\n",
            "madrid: 41\n",
            "democracia: 41\n",
            "ja: 41\n",
            "ara: 41\n",
            "molt: 41\n",
            "defensa: 39\n",
            "hacer: 39\n",
            "electoral: 39\n",
            "momento: 38\n",
            "quan: 38\n",
            "público: 37\n",
            "problema: 37\n",
            "aquest: 37\n",
            "barcelona: 37\n",
            "noticia: 37\n",
            "sense: 36\n",
            "des: 35\n",
            "això: 35\n",
            "cifuent: 34\n",
            "social: 34\n",
            "perder: 34\n",
            "cap: 34\n",
            "creer: 34\n",
            "correo: 34\n",
            "empresa: 33\n",
            "compañía: 33\n",
            "explicar: 33\n",
            "aquesta: 33\n",
            "historia: 33\n",
            "derecha: 32\n",
            "español: 32\n",
            "red: 32\n",
            "també: 32\n",
            "fet: 32\n",
            "són: 32\n",
            "fins: 32\n",
            "els: 32\n",
            "dejar: 32\n",
            "votar: 32\n",
            "guerra: 31\n",
            "demócrata: 31\n",
            "venir: 31\n",
            "\n",
            "Los 100 lemas más repetidos en el grupo 'Odio':\n",
            "mierda: 56\n",
            "español: 53\n",
            "puta: 53\n",
            "hijo: 47\n",
            "i: 40\n",
            "españa: 39\n",
            "asco: 37\n",
            "catalán: 32\n",
            "gente: 30\n",
            "per: 28\n",
            "catalanisme: 27\n",
            "político: 26\n",
            "país: 25\n",
            "q: 25\n",
            "año: 23\n",
            "gobierno: 23\n",
            "pagar: 22\n",
            "basura: 22\n",
            "l?independentisme: 22\n",
            "com: 22\n",
            "mujer: 21\n",
            "ver: 21\n",
            "dejar: 21\n",
            "pasar: 20\n",
            "vergüenza: 19\n",
            "tonto: 19\n",
            "és: 19\n",
            "mundo: 19\n",
            "dar: 18\n",
            "amb: 18\n",
            "poner: 18\n",
            "gentuza: 18\n",
            "madrid: 16\n",
            "haber: 16\n",
            "caso: 16\n",
            "vox: 16\n",
            "vida: 16\n",
            "ir: 15\n",
            "decir: 15\n",
            "persona: 15\n",
            "deber: 15\n",
            "@lavanguardia: 15\n",
            "madre: 15\n",
            "puto: 15\n",
            "culo: 15\n",
            "pp: 14\n",
            "cárcel: 14\n",
            "periódico: 14\n",
            "tener: 14\n",
            "el: 14\n",
            "partido: 13\n",
            "izquierda: 13\n",
            "salir: 13\n",
            "pensar: 13\n",
            "però: 13\n",
            "importar: 13\n",
            "seguir: 13\n",
            "hombre: 13\n",
            "miserable: 13\n",
            "noticia: 13\n",
            "ilegal: 13\n",
            "delincuente: 12\n",
            "cosa: 12\n",
            "estar: 12\n",
            "mirar: 12\n",
            "fascista: 12\n",
            "meter: 12\n",
            "maldito: 12\n",
            "corrupción: 11\n",
            "universidad: 11\n",
            "hacer: 11\n",
            "més: 11\n",
            "querer: 11\n",
            "trump: 11\n",
            "negro: 11\n",
            "cifuent: 10\n",
            "llegar: 10\n",
            "dinero: 10\n",
            "público: 10\n",
            "entender: 10\n",
            "derecho: 10\n",
            "permitir: 10\n",
            "hablar: 10\n",
            "actuar: 10\n",
            "tiempo: 10\n",
            "muerto: 10\n",
            "comunista: 10\n",
            "payaso: 10\n",
            "dais: 10\n",
            "venir: 10\n",
            "gustar: 10\n",
            "policía: 10\n",
            "extranjero: 10\n",
            "inmigrante: 10\n",
            "racista: 10\n",
            "actual: 9\n",
            "empezar: 9\n",
            "llamar: 9\n",
            "tomar: 9\n",
            "mentira: 9\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "# Cargar el modelo de spaCy para procesamiento de lenguaje natural\n",
        "nlp = spacy.load(\"es_core_news_md\")\n",
        "\n",
        "# Función para extraer lemas de un comentario\n",
        "def extraer_lemas(text):\n",
        "    doc = nlp(text)\n",
        "    # Extraer los lemas de los tokens que no son puntuación ni palabras de parada\n",
        "    lemas = [token.lemma_ for token in doc if not token.is_punct and not token.is_stop and not token.is_space]\n",
        "    return lemas\n",
        "\n",
        "# Aplicar la función para extraer lemas a cada comentario en el DataFrame\n",
        "data['Lemas'] = data['CONTENIDO A ANALIZAR'].apply(extraer_lemas)\n",
        "\n",
        "# Segmentar los datos en dos grupos basados en la 'INTENSIDAD'\n",
        "data_no_odio = data[data['INTENSIDAD'] == 0]\n",
        "data_odio = data[data['INTENSIDAD'] > 0]\n",
        "\n",
        "# Contar los lemas en cada grupo\n",
        "lemas_no_odio = Counter([lemma for sublist in data_no_odio['Lemas'] for lemma in sublist])\n",
        "lemas_odio = Counter([lemma for sublist in data_odio['Lemas'] for lemma in sublist])\n",
        "\n",
        "# Obtener los 100 lemas más comunes en cada grupo\n",
        "top_100_lemas_no_odio = lemas_no_odio.most_common(100)\n",
        "top_100_lemas_odio = lemas_odio.most_common(100)\n",
        "\n",
        "print(\"Los 100 lemas más repetidos en el grupo 'No Odio':\")\n",
        "for lemma, frequency in top_100_lemas_no_odio:\n",
        "    print(f\"{lemma}: {frequency}\")\n",
        "\n",
        "print(\"\\nLos 100 lemas más repetidos en el grupo 'Odio':\")\n",
        "for lemma, frequency in top_100_lemas_odio:\n",
        "    print(f\"{lemma}: {frequency}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMYK-vn9Ojnh"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. En el foro se explica que la columna a utilizar como comentarios es \"CONTENIDO A ANALIZAR\"\n",
        "2. Se utiliza la libreria spacy con el modelo preentrenado es_core_news_md para una mayor precisión\n",
        "3. Se utiliza la función extraer_lemas para extraer los lemas de un comentario, esta función es llamada mediante la columna CONTENIDO A ANALIZAR (\"comentarios\"), y asignamos su valor al arreglo data['Lemas']\n",
        "4. Segmentamos los datos en 2 grupos basados en la Intensidad data_no_odio y data_odio.\n",
        "5. Contamos los lemas en cada grupo y asignamos a lemas_no_odio, lemas_odio respectivamente.\n",
        "6. Obtenemos los 100 lemas repetidos de cada grupo\n",
        "7. Imprimimos los resultados"
      ],
      "metadata": {
        "id": "ASXwJbDHQ0op"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRkMoVNcOjnh"
      },
      "source": [
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 11.</span>\n",
        "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Es posible utilizar alguna de las características extraídas en las preguntas anteriores para determinar si un mensaje contiene odio? Justifica tu respuesta con el análisis estadístico que consideres necesario.</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsVJ8qUzOjnh",
        "outputId": "06c337b1-6023-4e3d-f82c-9ac90b0406fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.99      0.75       363\n",
            "           1       0.00      0.00      0.00       237\n",
            "\n",
            "    accuracy                           0.60       600\n",
            "   macro avg       0.30      0.50      0.38       600\n",
            "weighted avg       0.37      0.60      0.45       600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Incluye aquí el código generado para poder responder a tu pregunta\n",
        "# Cargar el modelo de spaCy para procesamiento de lenguaje natural\n",
        "nlp = spacy.load(\"es_core_news_md\")\n",
        "\n",
        "# Extraer características\n",
        "# Por ejemplo, número de entidades y longitud de comentarios como características simples\n",
        "data['Comment_Length'] = data['CONTENIDO A ANALIZAR'].apply(len)\n",
        "data['NER_Count'] = data['CONTENIDO A ANALIZAR'].apply(lambda x: len(nlp(x).ents))\n",
        "\n",
        "# Crear el DataFrame de características\n",
        "features = data[['Comment_Length', 'NER_Count']]\n",
        "\n",
        "# Crear la variable de salida directamente desde 'INTENSIDAD'\n",
        "y = data['INTENSIDAD'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo de regresión logística\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones sobre el conjunto de prueba\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Mostrar el informe de clasificación\n",
        "print(classification_report(y_test, predictions))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHx_xkswOjnh"
      },
      "source": [
        "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. En el foro se explica que la columna a utilizar como comentarios es \"CONTENIDO A ANALIZAR\"\n",
        "2. Se utiliza la libreria spacy con el modelo preentrenado es_core_news_md para una mayor precisión\n",
        "3. Extraemos las entidades y logitud de la columna CONTENIDO A ANALIZAR (\"Comentarios\") asignando a dos arreglos respectivamente data['Comment_Length'] y data['NER_Count']\n",
        "4. Creamos el DataFrame de características\n",
        "5. Creamos la variable de salida desde Intensidad\n",
        "6. Dividimos los datos en conjuntos de entrenamiento y prueba\n",
        "7. Crear y entrenar el modelo de regresión logística\n",
        "8. Realizar predicciones sobre el conjunto de prueba\n",
        "9. Imprimimos los resultados\n",
        "\n",
        "Análisis Estadístico para Justificar la utilización de Características\n",
        "Se puede utilizar.\n",
        "1. Análisis de Correlación para identificar si hay una correlación estadísticamente significativa entre las características mencionadas y la clasificación de los mensajes en categorías de odio o no odio.\n",
        "2. Regresión Logística para evaluar la capacidad predictiva de las características identificadas para clasificar los comentarios en grupos de odio y no odio.\n",
        "3. Análisis de Componentes Principales (PCA) para reducir la dimensionalidad de los datos de características para identificar las más significativas.\n",
        "\n"
      ],
      "metadata": {
        "id": "Rl7jq-dCSpuO"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}